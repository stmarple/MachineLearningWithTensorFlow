{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FFNN_MNST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stmarple/MachineLearningWithTensorFlow/blob/master/FFNN_MNST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KECr0nCgTICr",
        "colab_type": "text"
      },
      "source": [
        "# MNIST (aka Modified National Institute of Standards and Technology Database) \n",
        "is a large database of handwritten digits used for training various image processing systems.\n",
        "https://en.wikipedia.org/wiki/MNIST_database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1nHUfemQGqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXHHDol2Qfos",
        "colab_type": "text"
      },
      "source": [
        "### **Load and Prepare the MNIST Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5acM7z7wQNHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxkB2bNwQ2Ea",
        "colab_type": "text"
      },
      "source": [
        "### **Build the `tf.keras.Sequential` model by stacking layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJa8S8S4QxEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV7pIwSsRYg6",
        "colab_type": "text"
      },
      "source": [
        "### **Train and evaluate the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTBGUZZFQ6sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "eeb76406-2307-4a94-ca91-458dd21bb816"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2541 - acc: 0.9253\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1153 - acc: 0.9657\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0825 - acc: 0.9747\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0661 - acc: 0.9793\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0537 - acc: 0.9833\n",
            "10000/10000 - 0s - loss: 0.0664 - acc: 0.9784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06637940495018847, 0.9784]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80MEW10qvqbN",
        "colab_type": "text"
      },
      "source": [
        "# Classification of MNIST Digits\n",
        "https://medium.com/tebs-lab/how-to-classify-mnist-digits-with-different-neural-network-architectures-39c75a0f03e3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE4XpoJ2uqI9",
        "colab_type": "text"
      },
      "source": [
        "**Shape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cBmbK5bRg-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4f791003-8c73-42c3-a14e-fabf2b335c92"
      },
      "source": [
        "print('Training data shape: ', x_train.shape)\n",
        "print('Test data shape: ', x_test.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape:  (60000, 28, 28)\n",
            "Test data shape:  (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZOCD4yDvCdO",
        "colab_type": "text"
      },
      "source": [
        "**Flatten Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEyiRYHWuicJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_vector_size = 28**2\n",
        "x_train = x_train.reshape(x_train.shape[0], img_vector_size)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_vector_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqqBi2XSwi_9",
        "colab_type": "text"
      },
      "source": [
        "### Create a Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj8HO3gbvfDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "15709c7a-6b2c-468d-c67d-b8a942c74a43"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Setup train and test splits\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print('Training label shape: '   , y_train.shape) # (60000,) -- 60000 numbers (all 0-9)\n",
        "print('First 5 training labels: ', y_train[:5]) # [5, 0, 4, 1, 9]\n",
        "\n",
        "# Convert to \"one-hot\" vectors using the to_categorical function\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print('First 5 training lables as one-hot encoded vectors:\\n', y_train[:5])\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training label shape:  (60000,)\n",
            "First 5 training labels:  [5 0 4 1 9]\n",
            "First 5 training lables as one-hot encoded vectors:\n",
            " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cx4Q-4f4E-f",
        "colab_type": "text"
      },
      "source": [
        "### For fully connected neural networks, there are three essential questions that define the networkâ€™s architecture:\n",
        "1. How many layers are there?\n",
        "2. How many nodes are there in each of those layers?\n",
        "3. What transfer/activation function is used at each of those layers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smCnFVlc5N3f",
        "colab_type": "text"
      },
      "source": [
        "### There are 2 factors that contribute to the performance of a neural network: \n",
        "* The loss function  \n",
        "* The optimization algorithm used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaQ2aw3O6LCF",
        "colab_type": "text"
      },
      "source": [
        "Per the article mentioned above, the author selects:\n",
        "* A *common loss function*: **the categorical cross entropy** and \n",
        "* One of the simpler *optimization alogorithms*: **the stocastic gradient descent (SGD)**\n",
        "\n",
        "**What is cross entropy loss?**  It is a log loss that measures the performance of a classification model whose output is based on a probability between 0 and 1.\n",
        "\n",
        "More information on loss functions and optimiizers can be found here: https://ml-cheatsheet.readthedocs.io/en/latest/optimizers.html#sgd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_1b7gyg8zPr",
        "colab_type": "text"
      },
      "source": [
        "## Creating First Model\n",
        "Dense layers are \"fully connected\" layers\n",
        "Documentation: https://keras.io/models/sequential/\n",
        "\n",
        "The input layer requires the special input_shape parameter which should match the shape of our training data.\n",
        "\n",
        "The **image_size** is a created by flattening an image to **28 X 28 or 28^2 = 784**\n",
        "\n",
        "**num_classes** represents the number of output nodes or probabilities\n",
        "\n",
        "This model has **a single hidden layer**, **that has 32 nodes, or 32 biases** using the sigmoid activation function\n",
        "\n",
        "And, since there are 784 square units, on 1 layer, that has 32 nodes, there are **784 x 1 x 32 = 25,088 weights**\n",
        "\n",
        "Therefore, there are 25,088 + 32 biases = **25,120 parameters**\n",
        "\n",
        "There are 32 x 10, or **320 weights from hidden layer to output layer**.\n",
        "\n",
        "Each of the 10 nodes adds a single bias >> 25,120 par + 320 weights + 10 nodes = **25,450 total parameters**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWZwXyriwota",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "99fe79a3-bee0-4e1d-a376-612de404413f"
      },
      "source": [
        "from keras.layers import Dense \n",
        "from keras.models import Sequential \n",
        "\n",
        "image_size = 784 # 28*28\n",
        "num_classes = 10 # ten unique digits\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=32, activation='sigmoid', input_shape=(image_size,)))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEeqklEN_eir",
        "colab_type": "text"
      },
      "source": [
        "### This model contains a special activation function: the softmax.\n",
        "What makes it special is that it normalizes the values from the 10 output nodes in such a way that:\n",
        "* all the values are between 0 and 1\n",
        "* the sum of all 10 values = 1\n",
        "\n",
        "To put it another way, Softmax \"calculates the probabilities distribution of the event over 'n' different events\".  In this case, there are 10 possible probabilities, with the largest as the prediction vector.  These probabilities \"will be helpful when determining the target class for the given inputs\".\n",
        "\n",
        "More information on activation functions can be found here:\n",
        "https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeR2sqRrFL4O",
        "colab_type": "text"
      },
      "source": [
        "## Train and Evaluate The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V57f6_G9eZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "e057bbf2-5daf-4ed0-96bf-78a9f02baf26"
      },
      "source": [
        "model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.fit(x_train, y_train, epochs=5)\n",
        "#model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=5, validation_split=0.1)\n",
        "#loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-58b3ce737d96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#model.evaluate(x_test,  y_test, verbose=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, validation_split=0.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_5_input to have 2 dimensions, but got array with shape (60000, 28, 28)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haWxXCpGGECZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='best')\n",
        "plt.show()\n",
        "\n",
        "print(f'Test loss: {loss:.3}')\n",
        "print(f'Test accuracy: {accuracy:.3}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeGxhDgNFmIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}